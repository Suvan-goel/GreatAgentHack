{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"../assets/images/hackathon.png\" alt=\"Holistic AI Hackathon Logo\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "**Event**: [hackathon.holisticai.com](https://hackathon.holisticai.com)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Building ReAct Agents with LangGraph\n",
    "\n",
    "**Learn to build intelligent agents using LangGraph's prebuilt ReAct pattern**\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Understand**: What is a ReAct agent and how it differs from direct LLM calls\n",
    "2. **Build**: Your first ReAct agent using LangGraph's official implementation\n",
    "3. **Add Tools**: Integrate Valyu AI search for real-time information\n",
    "4. **Compare**: Agent performance with and without tools\n",
    "\n",
    "## What is ReAct?\n",
    "\n",
    "**ReAct** = **Reasoning** + **Acting**\n",
    "\n",
    "- Traditional approach (2022): LLM generates explicit \"Thought:\", \"Action:\", \"Observation:\" steps in text\n",
    "- Modern approach (2023-2025): LLMs use **function calling** - structured tool execution built into the model API\n",
    "- This tutorial uses the **modern approach** with LangGraph's prebuilt agent\n",
    "\n",
    "### Modern ReAct Pattern Flow\n",
    "\n",
    "```\n",
    "User Input\n",
    "    ‚Üì\n",
    "LLM Reasoning (implicit)\n",
    "    ‚Üì\n",
    "Decision: Need tools?\n",
    "    ‚îú‚îÄ‚Üí YES: Call tool ‚Üí Get results ‚Üí Loop back\n",
    "    ‚îî‚îÄ‚Üí NO: Generate final answer ‚Üí End\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install Dependencies\n",
    "\n",
    "Run this cell to install all required packages in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:07:38.574317Z",
     "start_time": "2025-11-14T22:07:38.095483Z"
    }
   },
   "source": [
    "# Install required packages\n",
    "!pip install -q \\\n",
    "    langgraph\\\n",
    "    langchain-core\\\n",
    "    langchain-openai\\\n",
    "    langchain-valyu \\\n",
    "    python-dotenv \\\n",
    "    requests\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All dependencies installed!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment\n",
    "\n",
    "**Recommended:**\n",
    "Set up Holistic AI Bedrock Proxy API credentials in `.env`:\n",
    "\n",
    "```bash\n",
    "HOLISTIC_AI_TEAM_ID=tutorials_api\n",
    "HOLISTIC_AI_API_TOKEN=your-token-here\n",
    "```\n",
    "\n",
    "[API Guide](../assets/api-guide.pdf)\n",
    "\n",
    "**Alternative:**\n",
    "If you prefer OpenAI:\n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=your-openai-api-key-here\n",
    "```\n",
    "\n",
    "**Optional:**\n",
    "```bash\n",
    "VALYU_API_KEY=your-valyu-api-key-here\n",
    "```\n",
    "\n",
    "**Note:** The tutorial uses Holistic AI Bedrock by default (recommended). OpenAI is optional - to use it, call get_chat_model(model_name, use_openai=True) and set OPENAI_API_KEY."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T14:30:29.394813Z",
     "start_time": "2025-11-15T14:30:28.984557Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ============================================\n",
    "# OPTION 1: Set API keys directly (Quick Start)\n",
    "# ============================================\n",
    "# Uncomment and set your keys here:\n",
    "# Recommended: Holistic AI Bedrock\n",
    "os.environ[\"HOLISTIC_AI_TEAM_ID\"] = \"tutorials_api\"\n",
    "os.environ[\"HOLISTIC_AI_API_TOKEN\"] = \"SIcWmrU0745_QHALRull6gGpTPu3q268zCqGMrbQP4E\"\n",
    "# Alternative: OpenAI\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key-here\"\n",
    "# Optional: Valyu\n",
    "os.environ[\"VALYU_API_KEY\"] = \"\"\n",
    "\n",
    "# ============================================\n",
    "# OPTION 2: Load from .env file (Recommended)\n",
    "# ============================================\n",
    "# Try to load from .env file in parent directory\n",
    "env_path = Path('../.env')\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"üìÑ Loaded configuration from .env file\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No .env file found - using environment variables or hardcoded keys\")\n",
    "\n",
    "# ============================================\n",
    "# Verify API keys are set\n",
    "# ============================================\n",
    "print(\"\\nüîë API Key Status:\")\n",
    "if os.getenv('HOLISTIC_AI_TEAM_ID') and os.getenv('HOLISTIC_AI_API_TOKEN'):\n",
    "    print(\"  ‚úÖ Holistic AI Bedrock credentials loaded (will use Bedrock)\")\n",
    "elif os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"  ‚ö†Ô∏è  OpenAI API key loaded (Bedrock credentials not set)\")\n",
    "    print(\"     üí° Tip: Set HOLISTIC_AI_TEAM_ID and HOLISTIC_AI_API_TOKEN to use Bedrock (recommended)\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  No API keys found\")\n",
    "    print(\"     Set Holistic AI Bedrock credentials (recommended) or OpenAI key\")\n",
    "\n",
    "if os.getenv('VALYU_API_KEY'):\n",
    "    key_preview = os.getenv('VALYU_API_KEY')[:10] + \"...\"\n",
    "    print(f\"  ‚úÖ Valyu API key loaded: {key_preview}\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  Valyu API key not found - search tool will not work\")\n",
    "\n",
    "print(\"\\nüìÅ Working directory:\", Path.cwd())\n",
    "\n",
    "# ============================================\n",
    "# Import Holistic AI Bedrock helper function\n",
    "# ============================================\n",
    "# Import from core module (recommended)\n",
    "import sys\n",
    "try:\n",
    "    # Import from same directory\n",
    "    from holistic_ai_bedrock import HolisticAIBedrockChat, get_chat_model\n",
    "    print(\"\\n‚úÖ Holistic AI Bedrock helper function loaded\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è  Could not import holistic_ai_bedrock - will use OpenAI only\")\n",
    "    print(\"   Make sure holistic_ai_bedrock.py exists in tutorials directory\")\n",
    "\n",
    "# Import official packages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(\"\\n‚úÖ All imports successful!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No .env file found - using environment variables or hardcoded keys\n",
      "\n",
      "üîë API Key Status:\n",
      "  ‚úÖ Holistic AI Bedrock credentials loaded (will use Bedrock)\n",
      "  ‚ö†Ô∏è  Valyu API key not found - search tool will not work\n",
      "\n",
      "üìÅ Working directory: /Users/mathisweil/Documents/University/Hackathon/GreatAgentHack/tutorials\n",
      "\n",
      "‚úÖ Holistic AI Bedrock helper function loaded\n",
      "\n",
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Helper Function\n",
    "\n",
    "This helper function uses by default the best available model:\n",
    "\n",
    "**Recommended:**\n",
    "- **Holistic AI Bedrock** - Uses Claude, Llama, Nova models via Bedrock Proxy\n",
    "- Set `HOLISTIC_AI_TEAM_ID` and `HOLISTIC_AI_API_TOKEN` in `.env`\n",
    "- [API Guide](../assets/api-guide.pdf)\n",
    "\n",
    "**Alternative:**\n",
    "- **OpenAI** - Uses OpenAI models (optional)\n",
    "\n",
    "You can use model names like:\n",
    "- `claude-3-5-sonnet` ‚Üí Uses Holistic AI Bedrock (Claude Sonnet) - **Recommended**\n",
    "- `claude-3-5-haiku` ‚Üí Uses Holistic AI Bedrock (Claude Haiku - faster)\n",
    "- `gpt-5-mini` ‚Üí Uses OpenAI (optional, requires use_openai=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the Difference\n",
    "\n",
    "### Direct LLM Call vs ReAct Agent\n",
    "\n",
    "| Aspect | Direct LLM Call | ReAct Agent |\n",
    "|--------|----------------|-------------|\n",
    "| **Pattern** | One-shot: question ‚Üí answer | Reasoning + Acting in a loop |\n",
    "| **Tools** | ‚ùå No tool access | ‚úÖ Can use search, APIs, databases |\n",
    "| **Multi-step** | ‚ùå Single response | ‚úÖ Can break down complex tasks |\n",
    "| **Self-correction** | ‚ùå Cannot retry | ‚úÖ Can reflect and improve |\n",
    "| **Use Case** | Simple Q&A, summarization | Research, planning, tool use |\n",
    "\n",
    "Let's see this in action!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:17:02.756608Z",
     "start_time": "2025-11-14T22:16:55.850024Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "# Example 1: Direct LLM Call (Simple)\n",
    "print(\"=\"*70)\n",
    "print(\"EXAMPLE 1: Direct LLM Call\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use the helper function - uses Holistic AI Bedrock by default\n",
    "llm = get_chat_model(\"claude-3-5-sonnet\")  # Uses Holistic AI Bedrock (recommended)\n",
    "\n",
    "question = \"What is quantum computing?\"\n",
    "print(f\"\\n‚ùì Question: {question}\")\n",
    "\n",
    "start_time = time.time()\n",
    "response = llm.invoke(question)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nüí¨ Response: {response.content}\")\n",
    "print(f\"\\n‚è±Ô∏è  Time: {elapsed:.2f}s\")\n",
    "print(\"\\n‚úÖ Simple and fast!\")\n",
    "print(\"‚ùå But... can't use tools, can't reason through steps, single response only\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXAMPLE 1: Direct LLM Call\n",
      "======================================================================\n",
      "\n",
      "‚ùì Question: What is quantum computing?\n",
      "\n",
      "üí¨ Response: Quantum computing is a type of computing that uses quantum mechanics principles to perform calculations and process information. Unlike classical computers that use bits (0s and 1s), quantum computers use quantum bits or \"qubits\" that can exist in multiple states simultaneously due to a phenomenon called superposition.\n",
      "\n",
      "Key aspects of quantum computing include:\n",
      "\n",
      "1. Superposition: Qubits can exist in multiple states at once, allowing quantum computers to process vast amounts of data simultaneously\n",
      "\n",
      "2. Entanglement: Qubits can be linked together in a way that the state of one qubit directly relates to the state of another, regardless of distance\n",
      "\n",
      "3. Potential applications:\n",
      "- Complex mathematical problems\n",
      "- Cryptography and security\n",
      "- Drug discovery and molecular modeling\n",
      "- Climate modeling\n",
      "- Financial modeling\n",
      "- Optimization problems\n",
      "\n",
      "4. Current limitations:\n",
      "- Maintaining qubit stability (decoherence)\n",
      "- Error correction\n",
      "- Scaling up quantum systems\n",
      "- Cost and complexity\n",
      "\n",
      "While still in early stages, quantum computing has the potential to solve certain problems exponentially faster than classical computers, particularly in areas like cryptography, optimization, and simulation of quantum systems.\n",
      "\n",
      "‚è±Ô∏è  Time: 6.90s\n",
      "\n",
      "‚úÖ Simple and fast!\n",
      "‚ùå But... can't use tools, can't reason through steps, single response only\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Comparison\n",
    "\n",
    "#### Direct LLM Call Flow\n",
    "```\n",
    "User Question ‚Üí LLM ‚Üí Response \n",
    "```\n",
    "- ‚ö° Fast and simple\n",
    "- ‚ùå Can't use tools, no multi-step reasoning\n",
    "\n",
    "#### ReAct Agent Flow  \n",
    "```\n",
    "User Question ‚Üí LLM (with tools bound)\n",
    "                    ‚Üì\n",
    "          Need to use a tool?\n",
    "                ‚Üô        ‚Üò\n",
    "              YES        NO\n",
    "               ‚Üì          ‚Üì\n",
    "        Execute Tool   Final Answer\n",
    "               ‚Üì\n",
    "        Get Results\n",
    "               ‚Üì\n",
    "        Loop back to LLM ‚Üê‚îò\n",
    "```\n",
    "- ‚úÖ Can use tools (search, APIs, databases)\n",
    "- ‚úÖ Multi-step reasoning and self-correction\n",
    "- ‚úÖ Full observability of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Your First ReAct Agent\n",
    "\n",
    "Now let's use **LangGraph's prebuilt `create_react_agent`** function. This is the official implementation that handles:\n",
    "- State management (message history)\n",
    "- Tool binding (native function calling)\n",
    "- Execution loop (reasoning ‚Üí acting ‚Üí observing)\n",
    "- Error handling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:20:12.507815Z",
     "start_time": "2025-11-14T22:20:05.172088Z"
    }
   },
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Example 2: ReAct Agent (no tools yet)\n",
    "print(\"=\"*70)\n",
    "print(\"EXAMPLE 2: ReAct Agent (No Tools)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create LLM using helper function\n",
    "llm = get_chat_model(\"claude-3-5-sonnet\")\n",
    "\n",
    "# Create ReAct agent with NO tools (for now)\n",
    "agent = create_react_agent(llm, tools=[])\n",
    "\n",
    "# Use the same question from Example 1\n",
    "question = \"What is quantum computing?\"\n",
    "print(f\"\\n‚ùì Same Question: {question}\")\n",
    "\n",
    "start_time = time.time()\n",
    "result = agent.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nüí¨ Response: {result['messages'][-1].content}\")\n",
    "print(f\"\\n‚è±Ô∏è  Time: {elapsed:.2f}s\")\n",
    "print(f\"üìä Messages in conversation: {len(result['messages'])}\")\n",
    "print(\"\\n‚úÖ Agent can maintain context, use tools (when provided), and handle multi-turn!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXAMPLE 2: ReAct Agent (No Tools)\n",
      "======================================================================\n",
      "\n",
      "‚ùì Same Question: What is quantum computing?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b5/l943h0ps19n8jnvktq7851bh0000gn/T/ipykernel_22980/3891153321.py:13: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(llm, tools=[])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Response: Quantum computing is a type of computing that uses quantum mechanics principles to process information. Unlike traditional computers that use bits (0s and 1s), quantum computers use quantum bits or \"qubits\" that can exist in multiple states simultaneously due to a phenomenon called superposition.\n",
      "\n",
      "Key features of quantum computing include:\n",
      "\n",
      "1. Superposition: Qubits can be in multiple states at once\n",
      "2. Entanglement: Qubits can be connected in ways that classical bits cannot\n",
      "3. Interference: Quantum states can be manipulated to amplify correct solutions\n",
      "\n",
      "Potential applications include:\n",
      "\n",
      "1. Complex optimization problems\n",
      "2. Cryptography and security\n",
      "3. Drug discovery and molecular modeling\n",
      "4. Climate modeling\n",
      "5. Financial modeling\n",
      "6. Artificial Intelligence\n",
      "\n",
      "While quantum computers are still in early stages of development, they have the potential to solve certain problems exponentially faster than classical computers. However, they face significant challenges in terms of maintaining qubit stability (dealing with decoherence) and scaling up to practical applications.\n",
      "\n",
      "Major tech companies like IBM, Google, and Microsoft, as well as numerous startups, are actively working on developing quantum computers and quantum computing applications.\n",
      "\n",
      "‚è±Ô∏è  Time: 7.33s\n",
      "üìä Messages in conversation: 2\n",
      "\n",
      "‚úÖ Agent can maintain context, use tools (when provided), and handle multi-turn!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "The agent:\n",
    "1. Received your question as a `HumanMessage`\n",
    "2. LLM processed it (no tools needed for this simple question)\n",
    "3. Generated an `AIMessage` with the answer\n",
    "4. Returned the full conversation state\n",
    "\n",
    "**Key difference from direct LLM call**: The agent maintains state and can loop through tool calls if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Understanding Valyu Search Tool\n",
    "\n",
    "Before adding tools to the agent, let's understand what the Valyu search tool does:\n",
    "\n",
    "**Valyu** is an AI-powered search engine that:\n",
    "- Searches across proprietary sources + web\n",
    "- Returns structured results with title, URL, content, relevance scores\n",
    "- Optimized for AI agents (not just humans)\n",
    "\n",
    "Let's test it directly first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Official Valyu Integration\n",
    "\n",
    "We'll use the official `langchain-valyu` package which provides:\n",
    "- **ValyuSearchTool**: Search tool compatible with LangChain agents\n",
    "- **ValyuRetriever**: For RAG (Retrieval-Augmented Generation) pipelines\n",
    "\n",
    "Documentation: https://python.langchain.com/docs/integrations/providers/valyu/"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:22:06.103188Z",
     "start_time": "2025-11-14T22:22:01.478736Z"
    }
   },
   "source": [
    "# Import official Valyu tool from langchain-valyu package\n",
    "from langchain_valyu import ValyuSearchTool\n",
    "\n",
    "# Create search tool with configuration\n",
    "search_tool = ValyuSearchTool(\n",
    "    valyu_api_key=os.getenv(\"VALYU_API_KEY\"),\n",
    "    # Optional: configure search parameters (can also be set per-call)\n",
    "    # search_type=\"all\",  # Search both proprietary and web sources\n",
    "    # max_num_results=5,   # Limit results\n",
    "    # relevance_threshold=0.5,  # Minimum relevance score\n",
    "    # max_price=20.0  # Maximum cost in dollars\n",
    ")\n",
    "\n",
    "# Test it directly\n",
    "print(\"üîç Testing Valyu Search Tool Directly\")\n",
    "print(\"=\"*70)\n",
    "test_query = \"latest developments in quantum computing\"\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "# Call the search tool\n",
    "search_results = search_tool._run(\n",
    "    query=test_query,\n",
    "    search_type=\"all\",\n",
    "    max_num_results=5\n",
    ")\n",
    "\n",
    "# Display results (truncated for readability)\n",
    "result_str = str(search_results)\n",
    "print(\"üìÑ Search Results (first 500 chars):\")\n",
    "print(\"-\"*70)\n",
    "print(result_str[:500] + \"...\" if len(result_str) > 500 else result_str)\n",
    "print(\"-\"*70)\n",
    "print(f\"\\nüìä Total data returned: {len(result_str)} characters\")\n",
    "print(\"‚úÖ This data will be passed to the agent to answer questions!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing Valyu Search Tool Directly\n",
      "======================================================================\n",
      "Query: latest developments in quantum computing\n",
      "\n",
      "üìÑ Search Results (first 500 chars):\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"error\": \"\",\n",
      "  \"tx_id\": \"tx_0f072ced-cdbf-4364-b0c6-4af0fdc7a55a\",\n",
      "  \"query\": \"latest developments in quantum computing\",\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"title\": \"News - Quantum Computing Report\",\n",
      "      \"url\": \"https://quantumcomputingreport.com/news/?utm_source=valyu.ai&utm_medium=referral\",\n",
      "      \"content\": \"# News\\n\\nRecent news items published within the last 6 months on quantum computing developments are listed below. Click on the hyperlinked item to go to the press relea...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üìä Total data returned: 94493 characters\n",
      "‚úÖ This data will be passed to the agent to answer questions!\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: The Power of Tools - WITH vs WITHOUT Search\n",
    "\n",
    "Now let's see the real magic! We'll ask the same question to:\n",
    "1. **Agent WITHOUT search** - Will give generic/outdated answer\n",
    "2. **Agent WITH search** - Will use real-time web data\n",
    "\n",
    "This demonstrates why tools are critical for ReAct agents."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:23:06.903934Z",
     "start_time": "2025-11-14T22:23:02.489085Z"
    }
   },
   "source": [
    "# Test question about recent events (requires current information)\n",
    "recent_question = \"What are the latest breakthroughs in quantum computing in 2025?\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 1: Agent WITHOUT Search\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚ùì Question: {recent_question}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "result_no_search = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=recent_question)]\n",
    "})\n",
    "elapsed_no_search = time.time() - start_time\n",
    "\n",
    "print(\"üí¨ Response (NO search):\")\n",
    "print(\"-\"*70)\n",
    "response_text = result_no_search['messages'][-1].content\n",
    "print(response_text[:400] + \"...\" if len(response_text) > 400 else response_text)\n",
    "print(\"-\"*70)\n",
    "print(f\"‚è±Ô∏è  Time: {elapsed_no_search:.2f}s\")\n",
    "print(f\"\\n‚ö†Ô∏è  Note: Generic answer, likely outdated or vague (LLM training data cutoff)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 1: Agent WITHOUT Search\n",
      "======================================================================\n",
      "‚ùì Question: What are the latest breakthroughs in quantum computing in 2025?\n",
      "\n",
      "üí¨ Response (NO search):\n",
      "----------------------------------------------------------------------\n",
      "I need to clarify something: I cannot provide information about quantum computing breakthroughs in 2025, as I have a knowledge cutoff date and cannot make claims about future events. I aim to be accurate and transparent about what I can and cannot discuss. I can provide information about recent quantum computing developments up to my last update, or we can discuss current trends and their potentia...\n",
      "----------------------------------------------------------------------\n",
      "‚è±Ô∏è  Time: 4.41s\n",
      "\n",
      "‚ö†Ô∏è  Note: Generic answer, likely outdated or vague (LLM training data cutoff)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:24:59.961268Z",
     "start_time": "2025-11-14T22:24:33.267409Z"
    }
   },
   "source": [
    "# Now create agent WITH search tool\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 2: Agent WITH Search\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create new agent with Valyu search tool (uses Holistic AI Bedrock by default)\n",
    "llm_with_tools = get_chat_model(\"claude-3-5-sonnet\")\n",
    "agent_with_search = create_react_agent(\n",
    "    llm_with_tools,\n",
    "    tools=[search_tool]  # Add the search tool!\n",
    ")\n",
    "\n",
    "print(f\"\\n‚ùì Same Question: {recent_question}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "result_with_search = agent_with_search.invoke({\n",
    "    \"messages\": [HumanMessage(content=recent_question)]\n",
    "})\n",
    "elapsed_with_search = time.time() - start_time\n",
    "\n",
    "print(\"üí¨ Response (WITH search):\")\n",
    "print(\"-\"*70)\n",
    "response_text = result_with_search['messages'][-1].content\n",
    "print(response_text[:600] + \"...\" if len(response_text) > 600 else response_text)\n",
    "print(\"-\"*70)\n",
    "print(f\"‚è±Ô∏è  Time: {elapsed_with_search:.2f}s\")\n",
    "print(f\"\\n‚úÖ Note: Real-time data, specific sources, up-to-date information!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST 2: Agent WITH Search\n",
      "======================================================================\n",
      "\n",
      "‚ùì Same Question: What are the latest breakthroughs in quantum computing in 2025?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b5/l943h0ps19n8jnvktq7851bh0000gn/T/ipykernel_22980/1140267269.py:8: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent_with_search = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Response (WITH search):\n",
      "----------------------------------------------------------------------\n",
      "Based on the search results, here are the major quantum computing breakthroughs in 2025:\n",
      "\n",
      "1. Microsoft's Majorana 1 Chip:\n",
      "- First quantum chip powered by a new Topological Core architecture using topoconductors\n",
      "- Can fit up to a million qubits on a single palm-sized chip\n",
      "- Uses Majorana particles to produce more reliable and scalable qubits\n",
      "- Aims to solve meaningful, industrial-scale problems\n",
      "\n",
      "2. Google's Willow Chip and Quantum Echoes Algorithm:\n",
      "- First-ever verifiable quantum algorithm running on hardware\n",
      "- Performs 13,000 times faster than classical supercomputers\n",
      "- Can compute molecular s...\n",
      "----------------------------------------------------------------------\n",
      "‚è±Ô∏è  Time: 26.68s\n",
      "\n",
      "‚úÖ Note: Real-time data, specific sources, up-to-date information!\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Happened Under the Hood?\n",
    "\n",
    "When you gave the agent search capabilities:\n",
    "\n",
    "1. **LLM received the question** and analyzed it\n",
    "2. **Decided it needed current info** (can't answer from training data)\n",
    "3. **Called the Valyu search tool** with structured arguments\n",
    "4. **Received search results** with current 2025 information\n",
    "5. **Synthesized the answer** using the retrieved data\n",
    "\n",
    "This is the **ReAct pattern** in action:\n",
    "- **Re**ason: \"I need current information\"\n",
    "- **Act**: Call search tool\n",
    "- **Observe**: Get results\n",
    "- **Respond**: Synthesize answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Inspect the Message Trace\n",
    "\n",
    "Let's look at the conversation history to see the ReAct loop in action."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:25:55.638228Z",
     "start_time": "2025-11-14T22:25:55.632560Z"
    }
   },
   "source": [
    "print(\"üìä Message Trace (WITH search):\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, msg in enumerate(result_with_search['messages']):\n",
    "    msg_type = type(msg).__name__\n",
    "    print(f\"\\n{i+1}. {msg_type}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    if msg_type == \"HumanMessage\":\n",
    "        print(f\"   User: {msg.content[:100]}...\")\n",
    "    \n",
    "    elif msg_type == \"AIMessage\":\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            print(f\"   AI decided to call tool: {msg.tool_calls[0]['name']}\")\n",
    "            print(f\"   Args: {msg.tool_calls[0]['args']}\")\n",
    "        else:\n",
    "            content_preview = msg.content[:150] + \"...\" if len(msg.content) > 150 else msg.content\n",
    "            print(f\"   AI response: {content_preview}\")\n",
    "    \n",
    "    elif msg_type == \"ToolMessage\":\n",
    "        content_preview = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "        print(f\"   Tool returned: {content_preview}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Total messages: {len(result_with_search['messages'])}\")\n",
    "print(\"\\nThis shows the complete ReAct loop: User ‚Üí AI (tool call) ‚Üí Tool ‚Üí AI (answer)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Message Trace (WITH search):\n",
      "======================================================================\n",
      "\n",
      "1. HumanMessage\n",
      "----------------------------------------------------------------------\n",
      "   User: What are the latest breakthroughs in quantum computing in 2025?...\n",
      "\n",
      "2. AIMessage\n",
      "----------------------------------------------------------------------\n",
      "   AI decided to call tool: valyu_deep_search\n",
      "   Args: {'query': 'major breakthroughs discoveries advances quantum computing', 'start_date': '2025-01-01', 'end_date': '2025-12-31', 'max_num_results': 10}\n",
      "\n",
      "3. ToolMessage\n",
      "----------------------------------------------------------------------\n",
      "   Tool returned: {\n",
      "  \"success\": true,\n",
      "  \"error\": \"\",\n",
      "  \"tx_id\": \"tx_1d0775c8-700c-4aac-a0f0-47b5b27e3139\",\n",
      "  \"query\":...\n",
      "\n",
      "4. AIMessage\n",
      "----------------------------------------------------------------------\n",
      "   AI response: Based on the search results, here are the major quantum computing breakthroughs in 2025:\n",
      "\n",
      "1. Microsoft's Majorana 1 Chip:\n",
      "- First quantum chip powered...\n",
      "\n",
      "======================================================================\n",
      "Total messages: 4\n",
      "\n",
      "This shows the complete ReAct loop: User ‚Üí AI (tool call) ‚Üí Tool ‚Üí AI (answer)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Try Multi-Turn Conversation\n",
    "\n",
    "ReAct agents maintain state, so you can have multi-turn conversations!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:28:05.249009Z",
     "start_time": "2025-11-14T22:27:25.521232Z"
    }
   },
   "source": [
    "print(\"üí¨ Multi-Turn Conversation Example\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Start a new conversation\n",
    "conversation = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"Search for the latest AI agent frameworks in 2025\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Turn 1\n",
    "print(\"\\nüë§ Turn 1: Search for the latest AI agent frameworks in 2025\")\n",
    "result1 = agent_with_search.invoke(conversation)\n",
    "print(f\"ü§ñ Agent: {result1['messages'][-1].content[:200]}...\\n\")\n",
    "\n",
    "# Turn 2 - follow up question (agent has context from turn 1)\n",
    "result1['messages'].append(\n",
    "    HumanMessage(content=\"Which one is best for production use?\")\n",
    ")\n",
    "print(\"üë§ Turn 2: Which one is best for production use?\")\n",
    "result2 = agent_with_search.invoke(result1)\n",
    "print(f\"ü§ñ Agent: {result2['messages'][-1].content[:200]}...\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ The agent remembers context from previous turns!\")\n",
    "print(f\"Total messages in conversation: {len(result2['messages'])}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Multi-Turn Conversation Example\n",
      "======================================================================\n",
      "\n",
      "üë§ Turn 1: Search for the latest AI agent frameworks in 2025\n",
      "ü§ñ Agent: Based on the search results, here are the most notable AI agent frameworks in 2025:\n",
      "\n",
      "1. LangChain\n",
      "- Remains one of the most popular and mature frameworks\n",
      "- Offers 500+ integrations with LLMs, database...\n",
      "\n",
      "üë§ Turn 2: Which one is best for production use?\n",
      "ü§ñ Agent: Based on the search results, the best framework for production use depends on your specific requirements, but here are the top contenders with their production-ready strengths:\n",
      "\n",
      "1. Microsoft Agent Fra...\n",
      "\n",
      "======================================================================\n",
      "‚úÖ The agent remembers context from previous turns!\n",
      "Total messages in conversation: 6\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned:\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Direct LLM vs ReAct Agents**\n",
    "   - Direct LLM: Fast, simple, single-step\n",
    "   - ReAct Agent: Multi-step reasoning, tool use, self-correction\n",
    "\n",
    "2. **Modern ReAct Pattern**\n",
    "   - Uses function calling (not text parsing like original 2022 paper)\n",
    "   - Structured tool execution via LLM APIs\n",
    "   - Message-based state management\n",
    "\n",
    "3. **LangGraph's `create_react_agent`**\n",
    "   - Official prebuilt implementation\n",
    "   - Handles state, tools, execution loop\n",
    "   - Production-ready pattern\n",
    "\n",
    "4. **The Power of Tools**\n",
    "   - Agents without tools: Limited to training data\n",
    "   - Agents with tools: Access to real-time information\n",
    "   - Valyu search: AI-optimized search engine\n",
    "\n",
    "### When to Use ReAct Agents\n",
    "\n",
    "‚úÖ **Use ReAct agents when you need:**\n",
    "- Real-time information (web search, APIs)\n",
    "- Multi-step reasoning (planning, breaking down tasks)\n",
    "- Tool execution (databases, calculators, APIs)\n",
    "- Self-correction and iteration\n",
    "\n",
    "‚ùå **Use direct LLM calls when:**\n",
    "- Simple Q&A (no external data needed)\n",
    "- Text generation, summarization\n",
    "- Speed is critical\n",
    "- Task is single-step\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue your learning:\n",
    "\n",
    "1. **02_custom_tools.ipynb** - Build your own custom tools\n",
    "2. **03_structured_output.ipynb** - Get JSON responses with Pydantic schemas\n",
    "3. **04_model_monitoring.ipynb** - Track costs, tokens, and carbon footprint\n",
    "\n",
    "---\n",
    "\n",
    "### Resources\n",
    "\n",
    "- LangGraph Docs: https://langchain-ai.github.io/langgraph/\n",
    "- ReAct Paper (2022): https://arxiv.org/abs/2210.03629\n",
    "- Valyu API: https://valyu.ai\n",
    "\n",
    "---\n",
    "\n",
    "**Pro Tip**: Always start with the simplest approach (direct LLM) and add complexity (agents, tools) only when needed. The best code is the simplest code that works!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
